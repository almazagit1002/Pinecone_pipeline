{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"Generate_summaries_research_with_agents\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Maza\\\\Desktop\\\\Pinecone_pipeline\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Maza\\\\Desktop\\\\Pinecone_pipeline'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class JsonSummaryConfig:\n",
    "    \"\"\"\n",
    "    Configuration class for JSON summary settings.\n",
    "    \n",
    "    This class holds configuration settings required for handling JSON summaries.\n",
    "    It includes paths for directories and files as well as dictionaries for prompt \n",
    "    generation and model settings.\n",
    "\n",
    "    Attributes:\n",
    "        root_dir (Path): The root directory where all related files and directories are located.\n",
    "        read_schema (Path): The path to the schema file used for reading or validating JSON data.\n",
    "        load_json_summary (Path): The path where the JSON summary will be loaded from or saved to.\n",
    "        prompt_generate_json_summary (dict): A dictionary containing prompts used for generating JSON summaries.\n",
    "        models (dict): A dictionary containing model configurations for generating summaries.\n",
    "    \"\"\"\n",
    "    root_dir: Path\n",
    "    read_schema:Path\n",
    "    load_json_summary: Path\n",
    "    prompt_generate_json_summary:dict\n",
    "    models: dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph\n",
    "from typing_extensions import TypedDict\n",
    "@dataclass(frozen=True)\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of our graph.\n",
    "\n",
    "    This TypedDict class defines the structure for storing the state of a graph\n",
    "    during its processing. It includes details about the input file, intermediate\n",
    "    summaries, feedback, final summary, and other relevant metadata.\n",
    "\n",
    "    Attributes:\n",
    "        initial_file (str): The initial file path or name used as input for the graph.\n",
    "        draft_json_summary (dict): A dictionary holding the draft version of the JSON summary.\n",
    "        json_feedback (dict): A dictionary holding feedback for the JSON summary.\n",
    "        final_json_summary (dict): A dictionary holding the final version of the JSON summary.\n",
    "        num_steps (int): The number of steps or iterations taken in the graph processing.\n",
    "       \n",
    "    \"\"\"\n",
    "    initial_file : str\n",
    "    draft_json_summary : dict\n",
    "    json_feedback : dict\n",
    "    final_json_summary : dict\n",
    "    num_steps : int\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from vector_db_pipeline.utils.common import load_json, read_yaml, create_directories,save_json, read_txt_to_list, load_set, read_file_with_encodings\n",
    "from pathlib import Path\n",
    "from langchain_core.messages import  HumanMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_groq import ChatGroq\n",
    "from dotenv import load_dotenv\n",
    "from vector_db_pipeline.constants import *\n",
    "from vector_db_pipeline import logger\n",
    "import json\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser, StrOutputParser\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        schema_filepath = SCHEMA_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH,\n",
    "        models_filepath = MODELS_FILE_PATH,\n",
    "        prompt_template = PROMPT_FILE_PATH):\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.schema = read_yaml(schema_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        self.models = read_yaml(models_filepath)\n",
    "        self.prompt_template = read_yaml(prompt_template)\n",
    "    \n",
    "        \n",
    "\n",
    "    \n",
    "    def get_json_summary_config(self) -> JsonSummaryConfig:\n",
    "        \"\"\"\n",
    "        Retrieves the configuration settings for JSON summary processing.\n",
    "\n",
    "        This method reads the configuration settings from the class instance's config attribute,\n",
    "        creates necessary directories, and initializes a JsonSummaryConfig object with the \n",
    "        retrieved settings.\n",
    "\n",
    "        Returns:\n",
    "            JsonSummaryConfig: An object containing configuration settings for JSON summary processing.\n",
    "        \"\"\"\n",
    "        config = self.config.json_summary\n",
    "        create_directories([config.root_dir])\n",
    "        \n",
    "        json_summary_config = JsonSummaryConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            read_schema = config.read_schema,\n",
    "            load_json_summary = config.load_json_summary,\n",
    "            prompt_generate_json_summary = self.prompt_template.generate_json_summary,\n",
    "            models = self.models,\n",
    "            \n",
    "        ) \n",
    "\n",
    "        return json_summary_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file_with_encodings(file_path):\n",
    "    \"\"\"\n",
    "    Tries to read a file with different encodings until successful.\n",
    "\n",
    "    Args:\n",
    "        file_path (Path): The path to the file to be read.\n",
    "\n",
    "    Returns:\n",
    "        str: The content of the file if read successfully, otherwise an empty string.\n",
    "    \"\"\"\n",
    "    encodings = ['utf-8', 'latin-1', 'iso-8859-1', 'windows-1252']\n",
    "    for encoding in encodings:\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding=encoding) as f:\n",
    "                content = f.read()\n",
    "            logger.info(f\"File content successfully read using encoding: {encoding}\")\n",
    "            return content\n",
    "        except UnicodeDecodeError:\n",
    "            logger.warning(f\"Failed to read file with encoding: {encoding}\")\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JsonSummary:\n",
    "    \"\"\"\n",
    "    A class to generate and manage JSON summaries using various agents and models.\n",
    "\n",
    "    Attributes:\n",
    "        config (JsonSummaryConfig): Configuration settings for JSON summary processing.\n",
    "    \"\"\"\n",
    "    def __init__(self, config:JsonSummaryConfig):\n",
    "        \"\"\"\n",
    "        Initializes the JsonSummary class with the provided configuration.\n",
    "\n",
    "        Args:\n",
    "            config (JsonSummaryConfig): Configuration settings for JSON summary processing.\n",
    "        \"\"\"\n",
    "        self.config = config\n",
    "\n",
    "   \n",
    "    \n",
    "    def configure_model_system(self):\n",
    "        \"\"\"\n",
    "        Configures the model system with the appropriate agents and prompts.\n",
    "\n",
    "        This method sets up the models, templates, and agents required for generating,\n",
    "        validating, and editing JSON summaries.\n",
    "        \"\"\"\n",
    "        model =self.config.models.Llama3\n",
    "        logger.info(f\"Working with model: {model}\")\n",
    "        llm = ChatGroq(temperature=0, model_name=model)\n",
    "        \n",
    "        #Agents\n",
    "\n",
    "        # summary generator agent \n",
    "        json_creator_promt = PromptTemplate(\n",
    "            template= self.config.prompt_generate_json_summary.agent_summary_json_creator,\n",
    "            input_variables=[\"content\"])\n",
    "        \n",
    "        self.json_summary_generator = json_creator_promt | llm | JsonOutputParser()\n",
    "        \n",
    "        # analyse summary and decides if it has correct format\n",
    "        data_type_json_route_prompt = PromptTemplate(\n",
    "            template= self.config.prompt_generate_json_summary.agent_edit_json_route,\n",
    "            input_variables=[\"file\"])\n",
    "        \n",
    "        self.data_type_json_route_generator = data_type_json_route_prompt | llm | StrOutputParser()\n",
    "\n",
    "        # if json format is not correct this agent provides feedback for the final editor to aply corrections\n",
    "        json_feedbak_prompt =  PromptTemplate(\n",
    "            template= self.config.prompt_generate_json_summary.agent_feedbak_json,\n",
    "            input_variables=[\"file\"])\n",
    "        \n",
    "        self.json_feedbak_generator = json_feedbak_prompt | llm | JsonOutputParser()\n",
    "\n",
    "\n",
    "        # Final agent produce the final json object using the draft from self.json_summary_generator\n",
    "        # and the feedback from json_feedbak_generator\n",
    "        json_editor_prompt =  PromptTemplate(\n",
    "            template= self.config.prompt_generate_json_summary.agent_rewrite_json,\n",
    "            input_variables=[\"file\", \"feedback\"])\n",
    "        self.json_editor_generator = json_editor_prompt | llm | JsonOutputParser()\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    def generate_json_summary_agent(self,state):\n",
    "        \"\"\"\n",
    "        Generates a JSON summary draft from the initial file.\n",
    "\n",
    "        Args:\n",
    "            state (dict): The current state of the processing, including the initial file and step count.\n",
    "\n",
    "        Returns:\n",
    "            dict: Updated state with the draft JSON summary and incremented step count.\n",
    "        \"\"\"\n",
    "        logger.info(f\"Creating JSON summary draft\")\n",
    "        initial_file= state['initial_file']\n",
    "        num_steps = int(state['num_steps'])\n",
    "        num_steps += 1\n",
    "\n",
    "        try:\n",
    "            draft_json_summary = self.json_summary_generator.invoke({\"content\": initial_file})\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in json summary generator agent: {e}\")\n",
    "        return {\"draft_json_summary\": draft_json_summary, \"num_steps\":num_steps}\n",
    "    \n",
    "    def json_format_route_agent(self, state):\n",
    "        \"\"\"\n",
    "        Determines if the JSON draft has the correct format.\n",
    "\n",
    "        Args:\n",
    "            state (dict): The current state of the processing, including the draft JSON summary and step count.\n",
    "\n",
    "        Returns:\n",
    "            str: 'edit_file' if the data type is incorrect, otherwise 'no_edit'.\n",
    "        \"\"\"\n",
    "        logger.info(f\"Checking JSON draft data type\")\n",
    "        draft_json_summary = state.get('draft_json_summary')\n",
    "    \n",
    "        if draft_json_summary is None:\n",
    "            logger.error(\"No draft JSON summary provided.\")\n",
    "            return None\n",
    "\n",
    "        try:\n",
    "            summary_type = self.data_type_json_route_generator.invoke({\"file\": draft_json_summary})\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error determining JSON draft data type: {e}\")\n",
    "            return None\n",
    "\n",
    "        if summary_type == 'text':\n",
    "            return 'edit_file'\n",
    "        else:\n",
    "            return 'no_edit'\n",
    "        \n",
    "    def feedback_json(self,state):\n",
    "        \"\"\"\n",
    "        Provides feedback for correcting the JSON draft if the format is incorrect.\n",
    "\n",
    "        Args:\n",
    "            state (dict): The current state of the processing, including the draft JSON summary and step count.\n",
    "\n",
    "        Returns:\n",
    "            dict: Updated state with the feedback for the JSON draft and incremented step count.\n",
    "        \"\"\"\n",
    "\n",
    "        logger.info(f\"JSON draft incorrect.... Producing feedback \")\n",
    "        draft_json_summary= state['draft_json_summary']\n",
    "        num_steps = int(state['num_steps'])\n",
    "        num_steps += 1\n",
    "        try:\n",
    "            json_feedback = self.json_feedbak_generator.invoke({\"draft_json\": draft_json_summary})\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error producing fedback: {e}\")\n",
    "      \n",
    "        return {\"json_feedback\": json_feedback, \"num_steps\":num_steps}\n",
    "\n",
    "    \n",
    "    def no_rewrite(self,state):\n",
    "        \"\"\"\n",
    "        Finalizes the JSON draft as the final JSON summary if no corrections are needed.\n",
    "\n",
    "        Args:\n",
    "            state (dict): The current state of the processing, including the draft JSON summary and step count.\n",
    "\n",
    "        Returns:\n",
    "            dict: Updated state with the final JSON summary and incremented step count.\n",
    "        \"\"\"\n",
    "\n",
    "        logger.info(\"JSON summary draft correct and assigned to final_json_summary\")\n",
    "        ## Get the state\n",
    "        draft_json_summary = state[\"draft_json_summary\"]\n",
    "        num_steps = state['num_steps']\n",
    "        num_steps += 1\n",
    "\n",
    "        return {\"final_json_summary\": draft_json_summary, \"num_steps\":num_steps}\n",
    "    \n",
    "    \n",
    "\n",
    "    def edit_file_agent(self,state):\n",
    "        \"\"\"\n",
    "        Produces the final JSON summary using the draft and feedback.\n",
    "\n",
    "        Args:\n",
    "            state (dict): The current state of the processing, including the draft JSON summary, feedback, and step count.\n",
    "\n",
    "        Returns:\n",
    "            dict: Updated state with the final JSON summary and incremented step count.\n",
    "        \"\"\"\n",
    "        \n",
    "        logger.info(f\"Acting on feedback and producing final JSON summary\")\n",
    "        draft_json_summary= state['draft_json_summary']\n",
    "        json_feedback = state['json_feedback']\n",
    "        num_steps = int(state['num_steps'])\n",
    "        num_steps += 1\n",
    "        \n",
    "        try:\n",
    "            final_json_summary = self.json_editor_generator.invoke({\"file\": draft_json_summary, \"feedback\":json_feedback })\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error acting on fedback to generate final json file: {e}\")\n",
    "\n",
    "\n",
    "        return {\"final_json_summary\": final_json_summary, \"num_steps\":num_steps}\n",
    "       \n",
    "    def state_printer(self,state):\n",
    "        \"\"\"\n",
    "        Prints the current state of the processing.\n",
    "\n",
    "        Args:\n",
    "            state (dict): The current state of the processing.\n",
    "        \"\"\"\n",
    "        if state['num_steps'] > 2 :\n",
    "            logger.info(\"---STATE PRINTER---\")\n",
    "            logger.info(f\"Draft Json Summary Type: {type(state['draft_json_summary'])} \\n\")\n",
    "            logger.info(f\"Feedback: {state['json_feedback']} \\n\")\n",
    "            logger.info(f\"Final Json Summary Type: {type(state['final_json_summary'])} \\n\" )\n",
    "            logger.info(f\"Num Steps: {state['num_steps']} \\n\")\n",
    "        else:\n",
    "            logger.info(\"---STATE PRINTER---\")\n",
    "            logger.info(f\"Draft Json Summary: {type(state['draft_json_summary'])} \\n\")\n",
    "            logger.info(f\"Final Json Summary: {type(state['final_json_summary'])} \\n\")\n",
    "            logger.info(f\"Num Steps: {state['num_steps']} \\n\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    def create_graph_agents(self, workflow):\n",
    "        \"\"\"\n",
    "        Creates and configures the agent workflow graph.\n",
    "\n",
    "        Args:\n",
    "            workflow (Workflow): The workflow object to which nodes and edges will be added.\n",
    "\n",
    "        Returns:\n",
    "            CompiledWorkflow: The compiled workflow ready for execution.\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        #nodes\n",
    "        workflow.add_node(\"generate_json_summary_agent\", self.generate_json_summary_agent) \n",
    "        workflow.add_node(\"feedback_json\", self.feedback_json)\n",
    "        workflow.add_node(\"edit_file_agent\", self.edit_file_agent)\n",
    "        workflow.add_node(\"no_rewrite\", self.no_rewrite)\n",
    "        workflow.add_node(\"state_printer\", self.state_printer)\n",
    "\n",
    "        #edges\n",
    "        workflow.set_entry_point(\"generate_json_summary_agent\")\n",
    "        workflow.add_conditional_edges(\n",
    "            \"generate_json_summary_agent\",\n",
    "            self.json_format_route_agent,\n",
    "            {\n",
    "                \"edit_file\": \"feedback_json\",\n",
    "                \"no_edit\": \"no_rewrite\",\n",
    "            },\n",
    "        )\n",
    "        workflow.add_edge(\"feedback_json\", \"edit_file_agent\")\n",
    "        workflow.add_edge(\"no_rewrite\", \"state_printer\")\n",
    "        workflow.add_edge(\"edit_file_agent\", \"state_printer\")\n",
    "        workflow.add_edge(\"state_printer\", END)\n",
    "\n",
    "        #compile\n",
    "        try:\n",
    "            app = workflow.compile()\n",
    "            logger.info(\"Agent graph created\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Agent graph error: {e}\")\n",
    "             \n",
    "        return  app\n",
    "    \n",
    "    def run_graph_agents(self, app,file_paths):\n",
    "        \"\"\"\n",
    "        Runs the agent workflow on a list of file paths to generate JSON summaries.\n",
    "\n",
    "        Args:\n",
    "            app (CompiledWorkflow): The compiled workflow to be executed.\n",
    "            file_paths (list[Path]): List of file paths to process.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        load_json_file = self.config.load_json_summary\n",
    "        logger.info(f\"Initializing agent summary orquestration\")\n",
    "        batch_size = 5\n",
    "\n",
    "\n",
    "        batches = [file_paths[i:i + batch_size] for i in range(0, len(file_paths), batch_size)]\n",
    "        \n",
    "        for idx, files_batch in enumerate(batches, 1):\n",
    "\n",
    "            if os.path.exists(Path(load_json_file)):\n",
    "                json_summaries = load_json(Path(load_json_file))\n",
    "                logger.info(f\"Json summaries readed\")\n",
    "            else:\n",
    "                json_summaries = {}\n",
    "                logger.info(f\"new Json summaries\")\n",
    "            \n",
    "            \n",
    "            logger.info(f\"------------------------------Batch: {idx}------------------------------\")\n",
    "            \n",
    "            for file_path in files_batch:\n",
    "                logger.info(f\"Starting summary of {file_path}\")\n",
    "                file_content = read_file_with_encodings(file_path)\n",
    "\n",
    "                if len(file_content)>0:\n",
    "                    filename = os.path.basename(file_path)\n",
    "                    json_summaries[filename] = {}\n",
    "                    json_summaries[filename]['FILE_PATH'] = str(file_path)\n",
    "                    \n",
    "                    inputs = {\"initial_file\": file_content,\"num_steps\":0}\n",
    "                    try:\n",
    "                        output = app.invoke(inputs)\n",
    "                        json_summaries[filename].update(output['final_json_summary'])\n",
    "                        logger.info(f\"{filename} summary success\")\n",
    "                \n",
    "                    except:\n",
    "                        logger.error(f\"Error in agent graph: {e}\")\n",
    "                   \n",
    "                else:\n",
    "                    logger.info(f\"{filename} empty.\")\n",
    "\n",
    "            try:\n",
    "                save_json(Path(load_json_file), json_summaries)\n",
    "                logger.info(f\"JSON summaries loaded to {load_json_file}\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error saving JSON summaries: {e}\")\n",
    "                return batches[idx:]\n",
    "        \n",
    "        return logger.info(f\"All batches proccessed\")\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-05-25 12:15:17,642: INFO: common: yaml file: config\\config.yaml loaded successfully:]\n",
      "[2024-05-25 12:15:17,646: INFO: common: yaml file: schema.yaml loaded successfully:]\n",
      "[2024-05-25 12:15:17,647: INFO: common: yaml file: params.yaml loaded successfully:]\n",
      "[2024-05-25 12:15:17,647: INFO: common: yaml file: models.yaml loaded successfully:]\n",
      "[2024-05-25 12:15:17,660: INFO: common: yaml file: prompt_template.yaml loaded successfully:]\n",
      "[2024-05-25 12:15:17,663: INFO: common: Directory already exists: artifacts/json_summary:]\n",
      "[2024-05-25 12:15:17,666: INFO: common: Files successfully loaded from: artifacts\\app_schema\\files_to_read.json:]\n",
      "[2024-05-25 12:15:17,668: INFO: 111454437: Working with model: llama3-70b-8192:]\n",
      "[2024-05-25 12:15:19,917: INFO: 111454437: Agent graph created:]\n",
      "[2024-05-25 12:15:19,918: INFO: 111454437: Initializing agent summary orquestration:]\n",
      "[2024-05-25 12:15:19,931: INFO: common: json file loaded succesfully from: artifacts\\json_summary\\json_summary.json:]\n",
      "[2024-05-25 12:15:19,936: INFO: 111454437: Json summaries readed:]\n",
      "[2024-05-25 12:15:19,937: INFO: 111454437: ------------------------------Batch: 1------------------------------:]\n",
      "[2024-05-25 12:15:19,938: INFO: 111454437: Starting summary of .\\Dockerfile:]\n",
      "[2024-05-25 12:15:19,947: INFO: 3250731370: File content successfully read using encoding: utf-8:]\n",
      "[2024-05-25 12:15:20,060: INFO: 111454437: Creating JSON summary draft:]\n",
      "[2024-05-25 12:15:20,826: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\":]\n",
      "[2024-05-25 12:15:20,861: INFO: 111454437: Checking JSON draft data type:]\n",
      "[2024-05-25 12:15:21,189: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\":]\n",
      "[2024-05-25 12:15:21,215: INFO: 111454437: JSON summary draft correct and assigned to final_json_summary:]\n",
      "[2024-05-25 12:15:21,248: INFO: 111454437: ---STATE PRINTER---:]\n",
      "[2024-05-25 12:15:21,248: INFO: 111454437: Draft Json Summary: <class 'dict'> \n",
      ":]\n",
      "[2024-05-25 12:15:21,248: INFO: 111454437: Final Json Summary: <class 'dict'> \n",
      ":]\n",
      "[2024-05-25 12:15:21,248: INFO: 111454437: Num Steps: 2 \n",
      ":]\n",
      "[2024-05-25 12:15:21,261: INFO: 111454437: Dockerfile summary success:]\n",
      "[2024-05-25 12:15:21,262: INFO: 111454437: Starting summary of .\\prompt_template.yaml:]\n",
      "[2024-05-25 12:15:21,264: INFO: 3250731370: File content successfully read using encoding: utf-8:]\n",
      "[2024-05-25 12:15:21,294: INFO: 111454437: Creating JSON summary draft:]\n",
      "[2024-05-25 12:15:22,203: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\":]\n",
      "[2024-05-25 12:15:22,234: INFO: 111454437: Checking JSON draft data type:]\n",
      "[2024-05-25 12:15:22,566: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\":]\n",
      "[2024-05-25 12:15:22,594: INFO: 111454437: JSON summary draft correct and assigned to final_json_summary:]\n",
      "[2024-05-25 12:15:22,619: INFO: 111454437: ---STATE PRINTER---:]\n",
      "[2024-05-25 12:15:22,620: INFO: 111454437: Draft Json Summary: <class 'dict'> \n",
      ":]\n",
      "[2024-05-25 12:15:22,621: INFO: 111454437: Final Json Summary: <class 'dict'> \n",
      ":]\n",
      "[2024-05-25 12:15:22,621: INFO: 111454437: Num Steps: 2 \n",
      ":]\n",
      "[2024-05-25 12:15:22,626: INFO: 111454437: prompt_template.yaml summary success:]\n",
      "[2024-05-25 12:15:22,626: INFO: 111454437: Starting summary of .\\src\\vector_db_pipeline\\config\\configuration.py:]\n",
      "[2024-05-25 12:15:22,626: INFO: 3250731370: File content successfully read using encoding: utf-8:]\n",
      "[2024-05-25 12:15:22,669: INFO: 111454437: Creating JSON summary draft:]\n",
      "[2024-05-25 12:15:23,796: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\":]\n",
      "[2024-05-25 12:15:23,813: INFO: 111454437: Checking JSON draft data type:]\n",
      "[2024-05-25 12:15:24,178: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\":]\n",
      "[2024-05-25 12:15:24,216: INFO: 111454437: JSON summary draft correct and assigned to final_json_summary:]\n",
      "[2024-05-25 12:15:24,240: INFO: 111454437: ---STATE PRINTER---:]\n",
      "[2024-05-25 12:15:24,242: INFO: 111454437: Draft Json Summary: <class 'dict'> \n",
      ":]\n",
      "[2024-05-25 12:15:24,243: INFO: 111454437: Final Json Summary: <class 'dict'> \n",
      ":]\n",
      "[2024-05-25 12:15:24,244: INFO: 111454437: Num Steps: 2 \n",
      ":]\n",
      "[2024-05-25 12:15:24,249: INFO: 111454437: configuration.py summary success:]\n",
      "[2024-05-25 12:15:24,249: INFO: 111454437: Starting summary of .\\src\\vector_db_pipeline\\utils\\__init__.py:]\n",
      "[2024-05-25 12:15:24,249: INFO: 3250731370: File content successfully read using encoding: utf-8:]\n",
      "[2024-05-25 12:15:24,249: INFO: 111454437: configuration.py empty.:]\n",
      "[2024-05-25 12:15:24,258: INFO: 111454437: Starting summary of .\\params.yaml:]\n",
      "[2024-05-25 12:15:24,260: INFO: 3250731370: File content successfully read using encoding: utf-8:]\n",
      "[2024-05-25 12:15:24,325: INFO: 111454437: Creating JSON summary draft:]\n",
      "[2024-05-25 12:15:24,825: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\":]\n",
      "[2024-05-25 12:15:24,841: INFO: 111454437: Checking JSON draft data type:]\n",
      "[2024-05-25 12:15:25,195: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\":]\n",
      "[2024-05-25 12:15:25,238: INFO: 111454437: JSON summary draft correct and assigned to final_json_summary:]\n",
      "[2024-05-25 12:15:25,280: INFO: 111454437: ---STATE PRINTER---:]\n",
      "[2024-05-25 12:15:25,281: INFO: 111454437: Draft Json Summary: <class 'dict'> \n",
      ":]\n",
      "[2024-05-25 12:15:25,281: INFO: 111454437: Final Json Summary: <class 'dict'> \n",
      ":]\n",
      "[2024-05-25 12:15:25,282: INFO: 111454437: Num Steps: 2 \n",
      ":]\n",
      "[2024-05-25 12:15:25,292: INFO: 111454437: params.yaml summary success:]\n",
      "[2024-05-25 12:15:25,297: INFO: common: json file saved at: artifacts\\json_summary\\json_summary.json:]\n",
      "[2024-05-25 12:15:25,298: INFO: 111454437: JSON summaries loaded to artifacts/json_summary/json_summary.json:]\n",
      "[2024-05-25 12:15:25,308: INFO: common: json file loaded succesfully from: artifacts\\json_summary\\json_summary.json:]\n",
      "[2024-05-25 12:15:25,314: INFO: 111454437: Json summaries readed:]\n",
      "[2024-05-25 12:15:25,315: INFO: 111454437: ------------------------------Batch: 2------------------------------:]\n",
      "[2024-05-25 12:15:25,316: INFO: 111454437: Starting summary of .\\src\\vector_db_pipeline\\components\\data_load.py:]\n",
      "[2024-05-25 12:15:25,318: INFO: 3250731370: File content successfully read using encoding: utf-8:]\n",
      "[2024-05-25 12:15:25,350: INFO: 111454437: Creating JSON summary draft:]\n",
      "[2024-05-25 12:15:26,395: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\":]\n",
      "[2024-05-25 12:15:26,443: INFO: 111454437: Checking JSON draft data type:]\n",
      "[2024-05-25 12:15:26,781: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\":]\n",
      "[2024-05-25 12:15:26,814: INFO: 111454437: JSON summary draft correct and assigned to final_json_summary:]\n",
      "[2024-05-25 12:15:26,825: INFO: 111454437: ---STATE PRINTER---:]\n",
      "[2024-05-25 12:15:26,825: INFO: 111454437: Draft Json Summary: <class 'dict'> \n",
      ":]\n",
      "[2024-05-25 12:15:26,825: INFO: 111454437: Final Json Summary: <class 'dict'> \n",
      ":]\n",
      "[2024-05-25 12:15:26,825: INFO: 111454437: Num Steps: 2 \n",
      ":]\n",
      "[2024-05-25 12:15:26,848: INFO: 111454437: data_load.py summary success:]\n",
      "[2024-05-25 12:15:26,852: INFO: 111454437: Starting summary of .\\schema.yaml:]\n",
      "[2024-05-25 12:15:26,852: INFO: 3250731370: File content successfully read using encoding: utf-8:]\n",
      "[2024-05-25 12:15:26,881: INFO: 111454437: Creating JSON summary draft:]\n",
      "[2024-05-25 12:15:27,329: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\":]\n",
      "[2024-05-25 12:15:27,367: INFO: 111454437: Checking JSON draft data type:]\n",
      "[2024-05-25 12:15:27,698: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\":]\n",
      "[2024-05-25 12:15:27,732: INFO: 111454437: JSON summary draft correct and assigned to final_json_summary:]\n",
      "[2024-05-25 12:15:27,755: INFO: 111454437: ---STATE PRINTER---:]\n",
      "[2024-05-25 12:15:27,757: INFO: 111454437: Draft Json Summary: <class 'dict'> \n",
      ":]\n",
      "[2024-05-25 12:15:27,758: INFO: 111454437: Final Json Summary: <class 'dict'> \n",
      ":]\n",
      "[2024-05-25 12:15:27,758: INFO: 111454437: Num Steps: 2 \n",
      ":]\n",
      "[2024-05-25 12:15:27,758: INFO: 111454437: schema.yaml summary success:]\n",
      "[2024-05-25 12:15:27,758: INFO: 111454437: Starting summary of .\\.vscode\\settings.json:]\n",
      "[2024-05-25 12:15:27,776: INFO: 3250731370: File content successfully read using encoding: utf-8:]\n",
      "[2024-05-25 12:15:27,810: INFO: 111454437: Creating JSON summary draft:]\n",
      "[2024-05-25 12:15:28,216: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\":]\n",
      "[2024-05-25 12:15:28,232: INFO: 111454437: Checking JSON draft data type:]\n",
      "[2024-05-25 12:15:28,446: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\":]\n",
      "[2024-05-25 12:15:28,462: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 3.000000 seconds:]\n",
      "[2024-05-25 12:15:31,767: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\":]\n",
      "[2024-05-25 12:15:31,806: INFO: 111454437: JSON summary draft correct and assigned to final_json_summary:]\n",
      "[2024-05-25 12:15:31,841: INFO: 111454437: ---STATE PRINTER---:]\n",
      "[2024-05-25 12:15:31,842: INFO: 111454437: Draft Json Summary: <class 'dict'> \n",
      ":]\n",
      "[2024-05-25 12:15:31,842: INFO: 111454437: Final Json Summary: <class 'dict'> \n",
      ":]\n",
      "[2024-05-25 12:15:31,842: INFO: 111454437: Num Steps: 2 \n",
      ":]\n",
      "[2024-05-25 12:15:31,842: INFO: 111454437: settings.json summary success:]\n",
      "[2024-05-25 12:15:31,842: INFO: 111454437: Starting summary of .\\src\\vector_db_pipeline\\constants\\__init__.py:]\n",
      "[2024-05-25 12:15:31,860: INFO: 3250731370: File content successfully read using encoding: utf-8:]\n",
      "[2024-05-25 12:15:31,894: INFO: 111454437: Creating JSON summary draft:]\n",
      "[2024-05-25 12:15:32,119: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\":]\n",
      "[2024-05-25 12:15:32,120: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 1.000000 seconds:]\n",
      "[2024-05-25 12:15:33,646: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\":]\n",
      "[2024-05-25 12:15:33,662: INFO: 111454437: Checking JSON draft data type:]\n",
      "[2024-05-25 12:15:33,892: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\":]\n",
      "[2024-05-25 12:15:33,892: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 7.000000 seconds:]\n",
      "[2024-05-25 12:15:41,282: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\":]\n",
      "[2024-05-25 12:15:41,310: INFO: 111454437: JSON summary draft correct and assigned to final_json_summary:]\n",
      "[2024-05-25 12:15:41,335: INFO: 111454437: ---STATE PRINTER---:]\n",
      "[2024-05-25 12:15:41,336: INFO: 111454437: Draft Json Summary: <class 'dict'> \n",
      ":]\n",
      "[2024-05-25 12:15:41,337: INFO: 111454437: Final Json Summary: <class 'dict'> \n",
      ":]\n",
      "[2024-05-25 12:15:41,338: INFO: 111454437: Num Steps: 2 \n",
      ":]\n",
      "[2024-05-25 12:15:41,344: INFO: 111454437: __init__.py summary success:]\n",
      "[2024-05-25 12:15:41,344: INFO: 111454437: Starting summary of .\\config\\config.yaml:]\n",
      "[2024-05-25 12:15:41,344: INFO: 3250731370: File content successfully read using encoding: utf-8:]\n",
      "[2024-05-25 12:15:41,377: INFO: 111454437: Creating JSON summary draft:]\n",
      "[2024-05-25 12:15:41,612: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\":]\n",
      "[2024-05-25 12:15:41,612: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 3.000000 seconds:]\n",
      "[2024-05-25 12:15:45,226: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\":]\n",
      "[2024-05-25 12:15:45,257: INFO: 111454437: Checking JSON draft data type:]\n",
      "[2024-05-25 12:15:45,477: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\":]\n",
      "[2024-05-25 12:15:45,477: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 12.000000 seconds:]\n",
      "[2024-05-25 12:16:00,110: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\":]\n",
      "[2024-05-25 12:16:00,148: INFO: 111454437: JSON summary draft correct and assigned to final_json_summary:]\n",
      "[2024-05-25 12:16:00,172: INFO: 111454437: ---STATE PRINTER---:]\n",
      "[2024-05-25 12:16:00,173: INFO: 111454437: Draft Json Summary: <class 'dict'> \n",
      ":]\n",
      "[2024-05-25 12:16:00,174: INFO: 111454437: Final Json Summary: <class 'dict'> \n",
      ":]\n",
      "[2024-05-25 12:16:00,176: INFO: 111454437: Num Steps: 2 \n",
      ":]\n",
      "[2024-05-25 12:16:00,176: INFO: 111454437: config.yaml summary success:]\n",
      "[2024-05-25 12:16:00,176: INFO: common: json file saved at: artifacts\\json_summary\\json_summary.json:]\n",
      "[2024-05-25 12:16:00,176: INFO: 111454437: JSON summaries loaded to artifacts/json_summary/json_summary.json:]\n",
      "[2024-05-25 12:16:00,200: INFO: common: json file loaded succesfully from: artifacts\\json_summary\\json_summary.json:]\n",
      "[2024-05-25 12:16:00,203: INFO: 111454437: Json summaries readed:]\n",
      "[2024-05-25 12:16:00,204: INFO: 111454437: ------------------------------Batch: 3------------------------------:]\n",
      "[2024-05-25 12:16:00,205: INFO: 111454437: Starting summary of .\\src\\vector_db_pipeline\\utils\\common.py:]\n",
      "[2024-05-25 12:16:00,218: INFO: 3250731370: File content successfully read using encoding: utf-8:]\n",
      "[2024-05-25 12:16:00,249: INFO: 111454437: Creating JSON summary draft:]\n",
      "[2024-05-25 12:16:01,876: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\":]\n",
      "[2024-05-25 12:16:01,897: INFO: 111454437: Checking JSON draft data type:]\n",
      "[2024-05-25 12:16:02,114: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\":]\n",
      "[2024-05-25 12:16:02,126: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 44.000000 seconds:]\n",
      "[2024-05-25 12:16:48,710: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\":]\n",
      "[2024-05-25 12:16:48,733: INFO: 111454437: JSON summary draft correct and assigned to final_json_summary:]\n",
      "[2024-05-25 12:16:48,761: INFO: 111454437: ---STATE PRINTER---:]\n",
      "[2024-05-25 12:16:48,761: INFO: 111454437: Draft Json Summary: <class 'dict'> \n",
      ":]\n",
      "[2024-05-25 12:16:48,762: INFO: 111454437: Final Json Summary: <class 'dict'> \n",
      ":]\n",
      "[2024-05-25 12:16:48,763: INFO: 111454437: Num Steps: 2 \n",
      ":]\n",
      "[2024-05-25 12:16:48,770: INFO: 111454437: common.py summary success:]\n",
      "[2024-05-25 12:16:48,771: INFO: 111454437: Starting summary of .\\directory_state.json:]\n",
      "[2024-05-25 12:16:48,779: INFO: 3250731370: File content successfully read using encoding: utf-8:]\n",
      "[2024-05-25 12:16:48,815: INFO: 111454437: Creating JSON summary draft:]\n",
      "[2024-05-25 12:16:49,030: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\":]\n",
      "[2024-05-25 12:16:49,044: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 2.000000 seconds:]\n",
      "[2024-05-25 12:16:51,544: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\":]\n",
      "[2024-05-25 12:16:51,562: INFO: 111454437: Checking JSON draft data type:]\n",
      "[2024-05-25 12:16:51,779: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\":]\n",
      "[2024-05-25 12:16:51,779: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 10.000000 seconds:]\n",
      "[2024-05-25 12:17:02,189: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\":]\n",
      "[2024-05-25 12:17:02,219: INFO: 111454437: JSON summary draft correct and assigned to final_json_summary:]\n",
      "[2024-05-25 12:17:02,245: INFO: 111454437: ---STATE PRINTER---:]\n",
      "[2024-05-25 12:17:02,245: INFO: 111454437: Draft Json Summary: <class 'dict'> \n",
      ":]\n",
      "[2024-05-25 12:17:02,245: INFO: 111454437: Final Json Summary: <class 'dict'> \n",
      ":]\n",
      "[2024-05-25 12:17:02,245: INFO: 111454437: Num Steps: 2 \n",
      ":]\n",
      "[2024-05-25 12:17:02,245: INFO: 111454437: directory_state.json summary success:]\n",
      "[2024-05-25 12:17:02,245: INFO: 111454437: Starting summary of .\\src\\vector_db_pipeline\\components\\__init__.py:]\n",
      "[2024-05-25 12:17:02,245: INFO: 3250731370: File content successfully read using encoding: utf-8:]\n",
      "[2024-05-25 12:17:02,260: INFO: 111454437: directory_state.json empty.:]\n",
      "[2024-05-25 12:17:02,261: INFO: 111454437: Starting summary of .\\src\\vector_db_pipeline\\components\\data_validation.py:]\n",
      "[2024-05-25 12:17:02,263: INFO: 3250731370: File content successfully read using encoding: utf-8:]\n",
      "[2024-05-25 12:17:02,296: INFO: 111454437: Creating JSON summary draft:]\n",
      "[2024-05-25 12:17:02,529: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\":]\n",
      "[2024-05-25 12:17:02,529: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 2.000000 seconds:]\n",
      "[2024-05-25 12:17:05,529: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\":]\n",
      "[2024-05-25 12:17:05,550: INFO: 111454437: Checking JSON draft data type:]\n",
      "[2024-05-25 12:17:05,762: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\":]\n",
      "[2024-05-25 12:17:05,762: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 24.000000 seconds:]\n",
      "[2024-05-25 12:17:30,162: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\":]\n",
      "[2024-05-25 12:17:30,193: INFO: 111454437: JSON summary draft correct and assigned to final_json_summary:]\n",
      "[2024-05-25 12:17:30,209: INFO: 111454437: ---STATE PRINTER---:]\n",
      "[2024-05-25 12:17:30,209: INFO: 111454437: Draft Json Summary: <class 'dict'> \n",
      ":]\n",
      "[2024-05-25 12:17:30,209: INFO: 111454437: Final Json Summary: <class 'dict'> \n",
      ":]\n",
      "[2024-05-25 12:17:30,209: INFO: 111454437: Num Steps: 2 \n",
      ":]\n",
      "[2024-05-25 12:17:30,224: INFO: 111454437: data_validation.py summary success:]\n",
      "[2024-05-25 12:17:30,224: INFO: 111454437: Starting summary of .\\exhalation_ignore.yaml:]\n",
      "[2024-05-25 12:17:30,224: INFO: 3250731370: File content successfully read using encoding: utf-8:]\n",
      "[2024-05-25 12:17:30,258: INFO: 111454437: Creating JSON summary draft:]\n",
      "[2024-05-25 12:17:30,485: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\":]\n",
      "[2024-05-25 12:17:30,486: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 4.000000 seconds:]\n",
      "[2024-05-25 12:17:35,033: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\":]\n",
      "[2024-05-25 12:17:35,049: INFO: 111454437: Checking JSON draft data type:]\n",
      "[2024-05-25 12:17:35,273: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\":]\n",
      "[2024-05-25 12:17:35,273: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 6.000000 seconds:]\n",
      "[2024-05-25 12:17:41,965: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\":]\n",
      "[2024-05-25 12:17:41,981: INFO: 111454437: JSON summary draft correct and assigned to final_json_summary:]\n",
      "[2024-05-25 12:17:42,019: INFO: 111454437: ---STATE PRINTER---:]\n",
      "[2024-05-25 12:17:42,019: INFO: 111454437: Draft Json Summary: <class 'dict'> \n",
      ":]\n",
      "[2024-05-25 12:17:42,019: INFO: 111454437: Final Json Summary: <class 'dict'> \n",
      ":]\n",
      "[2024-05-25 12:17:42,019: INFO: 111454437: Num Steps: 2 \n",
      ":]\n",
      "[2024-05-25 12:17:42,029: INFO: 111454437: exhalation_ignore.yaml summary success:]\n",
      "[2024-05-25 12:17:42,032: INFO: common: json file saved at: artifacts\\json_summary\\json_summary.json:]\n",
      "[2024-05-25 12:17:42,032: INFO: 111454437: JSON summaries loaded to artifacts/json_summary/json_summary.json:]\n",
      "[2024-05-25 12:17:42,048: INFO: common: json file loaded succesfully from: artifacts\\json_summary\\json_summary.json:]\n",
      "[2024-05-25 12:17:42,050: INFO: 111454437: Json summaries readed:]\n",
      "[2024-05-25 12:17:42,051: INFO: 111454437: ------------------------------Batch: 4------------------------------:]\n",
      "[2024-05-25 12:17:42,053: INFO: 111454437: Starting summary of .\\structure.txt:]\n",
      "[2024-05-25 12:17:42,064: INFO: 3250731370: File content successfully read using encoding: utf-8:]\n",
      "[2024-05-25 12:17:42,097: INFO: 111454437: Creating JSON summary draft:]\n",
      "[2024-05-25 12:17:42,331: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\":]\n",
      "[2024-05-25 12:17:42,331: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 1.000000 seconds:]\n",
      "[2024-05-25 12:17:46,448: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\":]\n",
      "[2024-05-25 12:17:46,468: INFO: 111454437: Checking JSON draft data type:]\n",
      "[2024-05-25 12:17:46,704: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\":]\n",
      "[2024-05-25 12:17:46,706: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 10.000000 seconds:]\n",
      "[2024-05-25 12:17:57,168: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\":]\n",
      "[2024-05-25 12:17:57,200: INFO: 111454437: JSON summary draft correct and assigned to final_json_summary:]\n",
      "[2024-05-25 12:17:57,213: INFO: 111454437: ---STATE PRINTER---:]\n",
      "[2024-05-25 12:17:57,228: INFO: 111454437: Draft Json Summary: <class 'dict'> \n",
      ":]\n",
      "[2024-05-25 12:17:57,228: INFO: 111454437: Final Json Summary: <class 'dict'> \n",
      ":]\n",
      "[2024-05-25 12:17:57,228: INFO: 111454437: Num Steps: 2 \n",
      ":]\n",
      "[2024-05-25 12:17:57,228: INFO: 111454437: structure.txt summary success:]\n",
      "[2024-05-25 12:17:57,228: INFO: 111454437: Starting summary of .\\main.py:]\n",
      "[2024-05-25 12:17:57,228: INFO: 3250731370: File content successfully read using encoding: utf-8:]\n",
      "[2024-05-25 12:17:57,260: INFO: 111454437: Creating JSON summary draft:]\n",
      "[2024-05-25 12:17:57,498: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\":]\n",
      "[2024-05-25 12:17:57,498: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 3.000000 seconds:]\n",
      "[2024-05-25 12:18:02,049: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\":]\n",
      "[2024-05-25 12:18:02,103: INFO: 111454437: Checking JSON draft data type:]\n",
      "[2024-05-25 12:18:02,327: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\":]\n",
      "[2024-05-25 12:18:02,327: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 12.000000 seconds:]\n",
      "[2024-05-25 12:18:14,720: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\":]\n",
      "[2024-05-25 12:18:14,752: INFO: 111454437: JSON summary draft correct and assigned to final_json_summary:]\n",
      "[2024-05-25 12:18:14,777: INFO: 111454437: ---STATE PRINTER---:]\n",
      "[2024-05-25 12:18:14,778: INFO: 111454437: Draft Json Summary: <class 'dict'> \n",
      ":]\n",
      "[2024-05-25 12:18:14,779: INFO: 111454437: Final Json Summary: <class 'dict'> \n",
      ":]\n",
      "[2024-05-25 12:18:14,781: INFO: 111454437: Num Steps: 2 \n",
      ":]\n",
      "[2024-05-25 12:18:14,789: INFO: 111454437: main.py summary success:]\n",
      "[2024-05-25 12:18:14,789: INFO: 111454437: Starting summary of .\\src\\vector_db_pipeline\\__init__.py:]\n",
      "[2024-05-25 12:18:14,789: INFO: 3250731370: File content successfully read using encoding: utf-8:]\n",
      "[2024-05-25 12:18:14,831: INFO: 111454437: Creating JSON summary draft:]\n",
      "[2024-05-25 12:18:15,065: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\":]\n",
      "[2024-05-25 12:18:15,067: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 3.000000 seconds:]\n",
      "[2024-05-25 12:18:18,521: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\":]\n",
      "[2024-05-25 12:18:18,536: INFO: 111454437: Checking JSON draft data type:]\n",
      "[2024-05-25 12:18:18,753: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\":]\n",
      "[2024-05-25 12:18:18,753: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 7.000000 seconds:]\n",
      "[2024-05-25 12:18:26,181: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\":]\n",
      "[2024-05-25 12:18:26,244: INFO: 111454437: JSON summary draft correct and assigned to final_json_summary:]\n",
      "[2024-05-25 12:18:26,264: INFO: 111454437: ---STATE PRINTER---:]\n",
      "[2024-05-25 12:18:26,264: INFO: 111454437: Draft Json Summary: <class 'dict'> \n",
      ":]\n",
      "[2024-05-25 12:18:26,264: INFO: 111454437: Final Json Summary: <class 'dict'> \n",
      ":]\n",
      "[2024-05-25 12:18:26,264: INFO: 111454437: Num Steps: 2 \n",
      ":]\n",
      "[2024-05-25 12:18:26,285: INFO: 111454437: __init__.py summary success:]\n",
      "[2024-05-25 12:18:26,285: INFO: 111454437: Starting summary of .\\src\\vector_db_pipeline\\config\\__init__.py:]\n",
      "[2024-05-25 12:18:26,285: INFO: 3250731370: File content successfully read using encoding: utf-8:]\n",
      "[2024-05-25 12:18:26,285: INFO: 111454437: __init__.py empty.:]\n",
      "[2024-05-25 12:18:26,285: INFO: 111454437: Starting summary of .\\data.yaml:]\n",
      "[2024-05-25 12:18:26,303: INFO: 3250731370: File content successfully read using encoding: utf-8:]\n",
      "[2024-05-25 12:18:26,352: INFO: 111454437: Creating JSON summary draft:]\n",
      "[2024-05-25 12:18:26,581: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\":]\n",
      "[2024-05-25 12:18:26,596: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 1.000000 seconds:]\n",
      "[2024-05-25 12:18:28,017: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\":]\n",
      "[2024-05-25 12:18:28,035: INFO: 111454437: Checking JSON draft data type:]\n",
      "[2024-05-25 12:18:28,247: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\":]\n",
      "[2024-05-25 12:18:28,247: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 5.000000 seconds:]\n",
      "[2024-05-25 12:18:33,682: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\":]\n",
      "[2024-05-25 12:18:33,722: INFO: 111454437: JSON summary draft correct and assigned to final_json_summary:]\n",
      "[2024-05-25 12:18:33,751: INFO: 111454437: ---STATE PRINTER---:]\n",
      "[2024-05-25 12:18:33,752: INFO: 111454437: Draft Json Summary: <class 'dict'> \n",
      ":]\n",
      "[2024-05-25 12:18:33,753: INFO: 111454437: Final Json Summary: <class 'dict'> \n",
      ":]\n",
      "[2024-05-25 12:18:33,753: INFO: 111454437: Num Steps: 2 \n",
      ":]\n",
      "[2024-05-25 12:18:33,753: INFO: 111454437: data.yaml summary success:]\n",
      "[2024-05-25 12:18:33,767: INFO: common: json file saved at: artifacts\\json_summary\\json_summary.json:]\n",
      "[2024-05-25 12:18:33,768: INFO: 111454437: JSON summaries loaded to artifacts/json_summary/json_summary.json:]\n",
      "[2024-05-25 12:18:33,780: INFO: common: json file loaded succesfully from: artifacts\\json_summary\\json_summary.json:]\n",
      "[2024-05-25 12:18:33,783: INFO: 111454437: Json summaries readed:]\n",
      "[2024-05-25 12:18:33,784: INFO: 111454437: ------------------------------Batch: 5------------------------------:]\n",
      "[2024-05-25 12:18:33,785: INFO: 111454437: Starting summary of .\\setup.py:]\n",
      "[2024-05-25 12:18:33,785: INFO: 3250731370: File content successfully read using encoding: utf-8:]\n",
      "[2024-05-25 12:18:33,819: INFO: 111454437: Creating JSON summary draft:]\n",
      "[2024-05-25 12:18:34,031: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\":]\n",
      "[2024-05-25 12:18:34,047: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 2.000000 seconds:]\n",
      "[2024-05-25 12:18:36,635: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\":]\n",
      "[2024-05-25 12:18:36,652: INFO: 111454437: Checking JSON draft data type:]\n",
      "[2024-05-25 12:18:36,882: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\":]\n",
      "[2024-05-25 12:18:36,882: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 9.000000 seconds:]\n",
      "[2024-05-25 12:18:46,249: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\":]\n",
      "[2024-05-25 12:18:46,281: INFO: 111454437: JSON summary draft correct and assigned to final_json_summary:]\n",
      "[2024-05-25 12:18:46,303: INFO: 111454437: ---STATE PRINTER---:]\n",
      "[2024-05-25 12:18:46,303: INFO: 111454437: Draft Json Summary: <class 'dict'> \n",
      ":]\n",
      "[2024-05-25 12:18:46,303: INFO: 111454437: Final Json Summary: <class 'dict'> \n",
      ":]\n",
      "[2024-05-25 12:18:46,303: INFO: 111454437: Num Steps: 2 \n",
      ":]\n",
      "[2024-05-25 12:18:46,316: INFO: 111454437: setup.py summary success:]\n",
      "[2024-05-25 12:18:46,317: INFO: 111454437: Starting summary of .\\src\\vector_db_pipeline\\pipeline\\GenerateAppStructure.py:]\n",
      "[2024-05-25 12:18:46,318: INFO: 3250731370: File content successfully read using encoding: utf-8:]\n",
      "[2024-05-25 12:18:46,352: INFO: 111454437: Creating JSON summary draft:]\n",
      "[2024-05-25 12:18:46,598: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\":]\n",
      "[2024-05-25 12:18:46,598: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 1.000000 seconds:]\n",
      "[2024-05-25 12:18:48,331: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\":]\n",
      "[2024-05-25 12:18:48,353: INFO: 111454437: Checking JSON draft data type:]\n",
      "[2024-05-25 12:18:48,570: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\":]\n",
      "[2024-05-25 12:18:48,570: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 13.000000 seconds:]\n",
      "[2024-05-25 12:19:02,532: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\":]\n",
      "[2024-05-25 12:19:02,557: INFO: 111454437: JSON summary draft correct and assigned to final_json_summary:]\n",
      "[2024-05-25 12:19:02,582: INFO: 111454437: ---STATE PRINTER---:]\n",
      "[2024-05-25 12:19:02,582: INFO: 111454437: Draft Json Summary: <class 'dict'> \n",
      ":]\n",
      "[2024-05-25 12:19:02,582: INFO: 111454437: Final Json Summary: <class 'dict'> \n",
      ":]\n",
      "[2024-05-25 12:19:02,588: INFO: 111454437: Num Steps: 2 \n",
      ":]\n",
      "[2024-05-25 12:19:02,588: INFO: 111454437: GenerateAppStructure.py summary success:]\n",
      "[2024-05-25 12:19:02,597: INFO: 111454437: Starting summary of .\\src\\vector_db_pipeline\\entity\\config_entity.py:]\n",
      "[2024-05-25 12:19:02,599: INFO: 3250731370: File content successfully read using encoding: utf-8:]\n",
      "[2024-05-25 12:19:02,638: INFO: 111454437: Creating JSON summary draft:]\n",
      "[2024-05-25 12:19:02,883: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\":]\n",
      "[2024-05-25 12:19:02,883: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 2.000000 seconds:]\n",
      "[2024-05-25 12:19:05,518: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\":]\n",
      "[2024-05-25 12:19:05,539: INFO: 111454437: Checking JSON draft data type:]\n",
      "[2024-05-25 12:19:05,766: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\":]\n",
      "[2024-05-25 12:19:05,766: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 10.000000 seconds:]\n",
      "[2024-05-25 12:19:16,232: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\":]\n",
      "[2024-05-25 12:19:16,257: INFO: 111454437: JSON summary draft correct and assigned to final_json_summary:]\n",
      "[2024-05-25 12:19:16,288: INFO: 111454437: ---STATE PRINTER---:]\n",
      "[2024-05-25 12:19:16,288: INFO: 111454437: Draft Json Summary: <class 'dict'> \n",
      ":]\n",
      "[2024-05-25 12:19:16,288: INFO: 111454437: Final Json Summary: <class 'dict'> \n",
      ":]\n",
      "[2024-05-25 12:19:16,288: INFO: 111454437: Num Steps: 2 \n",
      ":]\n",
      "[2024-05-25 12:19:16,298: INFO: 111454437: config_entity.py summary success:]\n",
      "[2024-05-25 12:19:16,300: INFO: 111454437: Starting summary of .\\my_set.pkl:]\n",
      "[2024-05-25 12:19:16,304: WARNING: 3250731370: Failed to read file with encoding: utf-8:]\n",
      "[2024-05-25 12:19:16,304: INFO: 3250731370: File content successfully read using encoding: latin-1:]\n",
      "[2024-05-25 12:19:16,348: INFO: 111454437: Creating JSON summary draft:]\n",
      "[2024-05-25 12:19:16,583: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\":]\n",
      "[2024-05-25 12:19:16,583: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 3.000000 seconds:]\n",
      "[2024-05-25 12:19:20,328: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\":]\n",
      "[2024-05-25 12:19:20,339: INFO: 111454437: Checking JSON draft data type:]\n",
      "[2024-05-25 12:19:20,557: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\":]\n",
      "[2024-05-25 12:19:20,565: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 16.000000 seconds:]\n",
      "[2024-05-25 12:19:36,940: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\":]\n",
      "[2024-05-25 12:19:36,966: INFO: 111454437: JSON summary draft correct and assigned to final_json_summary:]\n",
      "[2024-05-25 12:19:36,993: INFO: 111454437: ---STATE PRINTER---:]\n",
      "[2024-05-25 12:19:36,994: INFO: 111454437: Draft Json Summary: <class 'dict'> \n",
      ":]\n",
      "[2024-05-25 12:19:36,996: INFO: 111454437: Final Json Summary: <class 'dict'> \n",
      ":]\n",
      "[2024-05-25 12:19:37,002: INFO: 111454437: Num Steps: 2 \n",
      ":]\n",
      "[2024-05-25 12:19:37,014: INFO: 111454437: my_set.pkl summary success:]\n",
      "[2024-05-25 12:19:37,015: INFO: 111454437: Starting summary of .\\src\\vector_db_pipeline\\pipeline\\__init__.py:]\n",
      "[2024-05-25 12:19:37,017: INFO: 3250731370: File content successfully read using encoding: utf-8:]\n",
      "[2024-05-25 12:19:37,018: INFO: 111454437: my_set.pkl empty.:]\n",
      "[2024-05-25 12:19:37,021: INFO: common: json file saved at: artifacts\\json_summary\\json_summary.json:]\n",
      "[2024-05-25 12:19:37,022: INFO: 111454437: JSON summaries loaded to artifacts/json_summary/json_summary.json:]\n",
      "[2024-05-25 12:19:37,033: INFO: common: json file loaded succesfully from: artifacts\\json_summary\\json_summary.json:]\n",
      "[2024-05-25 12:19:37,036: INFO: 111454437: Json summaries readed:]\n",
      "[2024-05-25 12:19:37,037: INFO: 111454437: ------------------------------Batch: 6------------------------------:]\n",
      "[2024-05-25 12:19:37,038: INFO: 111454437: Starting summary of .\\my_set.json:]\n",
      "[2024-05-25 12:19:37,051: INFO: 3250731370: File content successfully read using encoding: utf-8:]\n",
      "[2024-05-25 12:19:37,092: INFO: 111454437: Creating JSON summary draft:]\n",
      "[2024-05-25 12:19:37,333: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\":]\n",
      "[2024-05-25 12:19:37,334: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 2.000000 seconds:]\n",
      "[2024-05-25 12:19:40,055: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\":]\n",
      "[2024-05-25 12:19:40,067: INFO: 111454437: Checking JSON draft data type:]\n",
      "[2024-05-25 12:19:40,300: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\":]\n",
      "[2024-05-25 12:19:40,300: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 14.000000 seconds:]\n",
      "[2024-05-25 12:19:54,701: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\":]\n",
      "[2024-05-25 12:19:54,735: INFO: 111454437: JSON summary draft correct and assigned to final_json_summary:]\n",
      "[2024-05-25 12:19:54,760: INFO: 111454437: ---STATE PRINTER---:]\n",
      "[2024-05-25 12:19:54,761: INFO: 111454437: Draft Json Summary: <class 'dict'> \n",
      ":]\n",
      "[2024-05-25 12:19:54,762: INFO: 111454437: Final Json Summary: <class 'dict'> \n",
      ":]\n",
      "[2024-05-25 12:19:54,764: INFO: 111454437: Num Steps: 2 \n",
      ":]\n",
      "[2024-05-25 12:19:54,772: INFO: 111454437: my_set.json summary success:]\n",
      "[2024-05-25 12:19:54,774: INFO: 111454437: Starting summary of .\\template.py:]\n",
      "[2024-05-25 12:19:54,776: INFO: 3250731370: File content successfully read using encoding: utf-8:]\n",
      "[2024-05-25 12:19:54,817: INFO: 111454437: Creating JSON summary draft:]\n",
      "[2024-05-25 12:19:55,051: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\":]\n",
      "[2024-05-25 12:19:55,052: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 3.000000 seconds:]\n",
      "[2024-05-25 12:19:58,918: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\":]\n",
      "[2024-05-25 12:19:58,938: INFO: 111454437: Checking JSON draft data type:]\n",
      "[2024-05-25 12:19:59,151: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\":]\n",
      "[2024-05-25 12:19:59,151: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 12.000000 seconds:]\n",
      "[2024-05-25 12:20:11,566: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\":]\n",
      "[2024-05-25 12:20:11,593: INFO: 111454437: JSON summary draft correct and assigned to final_json_summary:]\n",
      "[2024-05-25 12:20:11,618: INFO: 111454437: ---STATE PRINTER---:]\n",
      "[2024-05-25 12:20:11,618: INFO: 111454437: Draft Json Summary: <class 'dict'> \n",
      ":]\n",
      "[2024-05-25 12:20:11,618: INFO: 111454437: Final Json Summary: <class 'dict'> \n",
      ":]\n",
      "[2024-05-25 12:20:11,618: INFO: 111454437: Num Steps: 2 \n",
      ":]\n",
      "[2024-05-25 12:20:11,618: INFO: 111454437: template.py summary success:]\n",
      "[2024-05-25 12:20:11,633: INFO: 111454437: Starting summary of .\\src\\vector_db_pipeline\\entity\\__init__.py:]\n",
      "[2024-05-25 12:20:11,635: INFO: 3250731370: File content successfully read using encoding: utf-8:]\n",
      "[2024-05-25 12:20:11,636: INFO: 111454437: template.py empty.:]\n",
      "[2024-05-25 12:20:11,638: INFO: 111454437: Starting summary of .\\models.yaml:]\n",
      "[2024-05-25 12:20:11,640: INFO: 3250731370: File content successfully read using encoding: utf-8:]\n",
      "[2024-05-25 12:20:11,672: INFO: 111454437: Creating JSON summary draft:]\n",
      "[2024-05-25 12:20:11,885: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\":]\n",
      "[2024-05-25 12:20:11,885: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 1.000000 seconds:]\n",
      "[2024-05-25 12:20:14,118: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\":]\n",
      "[2024-05-25 12:20:14,141: INFO: 111454437: Checking JSON draft data type:]\n",
      "[2024-05-25 12:20:14,367: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\":]\n",
      "[2024-05-25 12:20:14,368: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 5.000000 seconds:]\n",
      "[2024-05-25 12:20:19,669: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\":]\n",
      "[2024-05-25 12:20:19,710: INFO: 111454437: JSON summary draft correct and assigned to final_json_summary:]\n",
      "[2024-05-25 12:20:19,736: INFO: 111454437: ---STATE PRINTER---:]\n",
      "[2024-05-25 12:20:19,737: INFO: 111454437: Draft Json Summary: <class 'dict'> \n",
      ":]\n",
      "[2024-05-25 12:20:19,738: INFO: 111454437: Final Json Summary: <class 'dict'> \n",
      ":]\n",
      "[2024-05-25 12:20:19,740: INFO: 111454437: Num Steps: 2 \n",
      ":]\n",
      "[2024-05-25 12:20:19,747: INFO: 111454437: models.yaml summary success:]\n",
      "[2024-05-25 12:20:19,748: INFO: 111454437: Starting summary of .\\exhalation.py:]\n",
      "[2024-05-25 12:20:19,750: INFO: 3250731370: File content successfully read using encoding: utf-8:]\n",
      "[2024-05-25 12:20:19,785: INFO: 111454437: Creating JSON summary draft:]\n",
      "[2024-05-25 12:20:20,008: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\":]\n",
      "[2024-05-25 12:20:20,008: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 2.000000 seconds:]\n",
      "[2024-05-25 12:20:23,206: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\":]\n",
      "[2024-05-25 12:20:23,226: INFO: 111454437: Checking JSON draft data type:]\n",
      "[2024-05-25 12:20:23,452: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\":]\n",
      "[2024-05-25 12:20:23,452: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 7.000000 seconds:]\n",
      "[2024-05-25 12:20:30,834: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\":]\n",
      "[2024-05-25 12:20:30,860: INFO: 111454437: JSON summary draft correct and assigned to final_json_summary:]\n",
      "[2024-05-25 12:20:30,885: INFO: 111454437: ---STATE PRINTER---:]\n",
      "[2024-05-25 12:20:30,885: INFO: 111454437: Draft Json Summary: <class 'dict'> \n",
      ":]\n",
      "[2024-05-25 12:20:30,885: INFO: 111454437: Final Json Summary: <class 'dict'> \n",
      ":]\n",
      "[2024-05-25 12:20:30,885: INFO: 111454437: Num Steps: 2 \n",
      ":]\n",
      "[2024-05-25 12:20:30,885: INFO: 111454437: exhalation.py summary success:]\n",
      "[2024-05-25 12:20:30,902: INFO: common: json file saved at: artifacts\\json_summary\\json_summary.json:]\n",
      "[2024-05-25 12:20:30,903: INFO: 111454437: JSON summaries loaded to artifacts/json_summary/json_summary.json:]\n",
      "[2024-05-25 12:20:30,907: INFO: common: json file loaded succesfully from: artifacts\\json_summary\\json_summary.json:]\n",
      "[2024-05-25 12:20:30,918: INFO: 111454437: Json summaries readed:]\n",
      "[2024-05-25 12:20:30,920: INFO: 111454437: ------------------------------Batch: 7------------------------------:]\n",
      "[2024-05-25 12:20:30,921: INFO: 111454437: Starting summary of .\\src\\vector_db_pipeline\\components\\generate_app_structure.py:]\n",
      "[2024-05-25 12:20:30,924: INFO: 3250731370: File content successfully read using encoding: utf-8:]\n",
      "[2024-05-25 12:20:30,968: INFO: 111454437: Creating JSON summary draft:]\n",
      "[2024-05-25 12:20:31,220: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\":]\n",
      "[2024-05-25 12:20:31,220: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 2.000000 seconds:]\n",
      "[2024-05-25 12:20:34,269: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\":]\n",
      "[2024-05-25 12:20:34,301: INFO: 111454437: Checking JSON draft data type:]\n",
      "[2024-05-25 12:20:34,519: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\":]\n",
      "[2024-05-25 12:20:34,519: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 30.000000 seconds:]\n",
      "[2024-05-25 12:21:05,870: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\":]\n",
      "[2024-05-25 12:21:05,903: INFO: 111454437: JSON summary draft correct and assigned to final_json_summary:]\n",
      "[2024-05-25 12:21:05,930: INFO: 111454437: ---STATE PRINTER---:]\n",
      "[2024-05-25 12:21:05,932: INFO: 111454437: Draft Json Summary: <class 'dict'> \n",
      ":]\n",
      "[2024-05-25 12:21:05,933: INFO: 111454437: Final Json Summary: <class 'dict'> \n",
      ":]\n",
      "[2024-05-25 12:21:05,935: INFO: 111454437: Num Steps: 2 \n",
      ":]\n",
      "[2024-05-25 12:21:05,945: INFO: 111454437: generate_app_structure.py summary success:]\n",
      "[2024-05-25 12:21:05,946: INFO: 111454437: Starting summary of .\\src\\vector_db_pipeline\\components\\data_ingestion.py:]\n",
      "[2024-05-25 12:21:05,948: INFO: 3250731370: File content successfully read using encoding: utf-8:]\n",
      "[2024-05-25 12:21:05,969: INFO: 111454437: Creating JSON summary draft:]\n",
      "[2024-05-25 12:21:06,220: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\":]\n",
      "[2024-05-25 12:21:06,220: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 3.000000 seconds:]\n",
      "[2024-05-25 12:21:10,703: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\":]\n",
      "[2024-05-25 12:21:10,722: INFO: 111454437: Checking JSON draft data type:]\n",
      "[2024-05-25 12:21:10,941: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\":]\n",
      "[2024-05-25 12:21:10,942: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 23.000000 seconds:]\n",
      "[2024-05-25 12:21:34,944: INFO: _client: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\":]\n",
      "[2024-05-25 12:21:34,979: INFO: 111454437: JSON summary draft correct and assigned to final_json_summary:]\n",
      "[2024-05-25 12:21:35,004: INFO: 111454437: ---STATE PRINTER---:]\n",
      "[2024-05-25 12:21:35,005: INFO: 111454437: Draft Json Summary: <class 'dict'> \n",
      ":]\n",
      "[2024-05-25 12:21:35,006: INFO: 111454437: Final Json Summary: <class 'dict'> \n",
      ":]\n",
      "[2024-05-25 12:21:35,008: INFO: 111454437: Num Steps: 2 \n",
      ":]\n",
      "[2024-05-25 12:21:35,016: INFO: 111454437: data_ingestion.py summary success:]\n",
      "[2024-05-25 12:21:35,020: INFO: common: json file saved at: artifacts\\json_summary\\json_summary.json:]\n",
      "[2024-05-25 12:21:35,020: INFO: 111454437: JSON summaries loaded to artifacts/json_summary/json_summary.json:]\n",
      "[2024-05-25 12:21:35,020: INFO: 111454437: All batches proccessed:]\n",
      "[2024-05-25 12:21:35,020: INFO: 1298268381: Plot comparision latency: 377.3836 seconds:]\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "json_summary_config = ConfigurationManager()\n",
    "config_json = json_summary_config.get_json_summary_config()\n",
    "files_in_app = list(load_set(Path(config_json.read_schema)))\n",
    "\n",
    "generate_json_summary = JsonSummary(config_json)\n",
    "\n",
    "\n",
    "generate_json_summary.configure_model_system()\n",
    "app = generate_json_summary.create_graph_agents(StateGraph(GraphState))\n",
    "generate_json_summary.run_graph_agents(app,files_in_app)\n",
    "logger.info(f\"Plot comparision latency: {(time.time() - start):.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
